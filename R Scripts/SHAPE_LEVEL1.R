# The R script for SHAPE: Spatial Health and Population Estimator - LEVEL ONE
# Code generated by: Emma Von Hoene
# Affiliation: George Mason University, Fairfax, VA, USA
# Contact: evonhoen@gmu.edu
# Adapted from: https://rpubs.com/robinlovelace/5089 ; https://www.taylorfrancis.com/books/mono/10.1201/9781315381640/spatial-microsimulation-robin-lovelace-morgane-dumont 
# Description: The script written to generate synthetic populations and small area estimates (SAE) from public health surveys and spatially aggregated data. 
# It is important to note that the data processing of the individual level survey and spatially aggregated datasets was completed prior to executing this script
# This code is adaptable for other researchers using other datasets to generate synthetic populations and SAEs for various applications, and any location and time period




########################## LOAD AND INSTALL REQUIRED PACKAGES########################## 
install.packages(c("readxl", "dplyr", "writexl", "tidyr"))

library(readxl)
library(dplyr)
library(writexl)
library(tidyr)



########################## READING IN INDIVIDUAL LEVEL SURVEY AND SPATIALLY AGGREGATED DATASETS ######################################

##### --- Individual-level Health Survey data --- #####
## This dataset was processed before this script, where each attribute (e.g., gender) was created for each category (e.g., male and female) and filled accordingly

# Read in the individual-level health survey data (Excel) 
#data <- read_excel("Insert File Path here!.xlsx")

# Read in the individual-level health survey data (csv) 
data <- read.csv("BRFSS_22_sampled_stratified.csv")

# Select only attributes used as 'predictors' in the IPF fitting process, keep the ID column (ID, gender, race, age, education, etc.)
selected_data <- select(data, ID, male, female, race1, race2, race3, race4, 
                        age1, age2, age3, age4, n_bach, bach, income1, income2, income3, income4,
                        insured, n_insured, urban, n_urban)

# Convert matrix into a dataframe
selected_data <- data.frame(selected_data) 


## CHECKING DATA CONSTRAINTS: This step is critical - all input data must meet these requirements to work correctly in IPF ##

## First, Checking Individual level data (sum should equal number of individuals (e.g., 9946) multiplied by number of variables (e.g. 7) -- (9946*7 = 69622))

# Select all columns except the first ID column
data_excluding_first <- selected_data[, -1]

# Calculate the sum of each column
column_sums <- colSums(data_excluding_first, na.rm = TRUE)

# Sum the column sums to get the total
total_sum <- sum(column_sums)

# Print the total sum
print(total_sum)

## Second, Checking individual level predictor variables
## The sum of each group (e.g., gender: male and female, or education: Bachelors or higher and no bachelors degree) should equal to total number of records
## Therefore, each of the following lines of code should output TRUE!

# Obtain number of responses/rows from the input survey data
n <- nrow(selected_data)

# calculate sum within each predictor group, and check if it matches with number of responses in the survey
sum(selected_data$male) + sum(selected_data$female) == n
sum(selected_data$race1) + sum(selected_data$race2) + sum(selected_data$race3) + sum(selected_data$race4) == n
sum(selected_data$age1) + sum(selected_data$age2) + sum(selected_data$age3) + sum(selected_data$age4) == n
sum(selected_data$n_bach) + sum(selected_data$bach) == n
sum(selected_data$income1) + sum(selected_data$income2) + sum(selected_data$income3) + sum(selected_data$income4) == n
sum(selected_data$insured) + sum(selected_data$n_insured) == n
sum(selected_data$urban) + sum(selected_data$n_urban) == n

## Third, Checking for no negative values, this should return FALSE
any(selected_data < 0, na.rm = TRUE)

##### --- Spatial aggregated data --- #####

# Read in spatially aggregated data (this data should also include a column that has total population count per geographic unit!)
census <- read_excel("county_spatial_ipf_data_2023_PART1.xlsx")

# Filtering data to only include for a specific area (e.g., state)
# census <- census %>%
#   filter(State == "FL")


# Selecting only attributes used as 'predictors' in the IPF fitting process, keep the GEOID column (FIPS, gender, race, age, education, etc.)
census_select <- select(census, FIPS, male, female, race1, race2, race3, race4, age1, age2, age3, age4, n_bach, bach, income1, income2, income3,income4, 
                        insured, n_insured, urban, n_urban)

# Convert matrix into a dataframe
census_select <- data.frame(census_select) 

# For every variable (except GEOID), changing values of 0 to 0.0001 so it works with IPF
census_select <- census_select %>%
  mutate_at(vars(-FIPS), ~ ifelse(. == 0, 0.000001, .))

## CHECKING DATA CONSTRAINTS: This step is critical - all input data must meet these requirements to work correctly in IPF ##

## First, Checking census level predictor variables
## The sum of each group (e.g., gender: male and female, or education: Bachelors or higher and no bachelors degree) should equal to total population variable
## Therefore, each of the following lines of code should output ZERO!

# Calculate total difference across all geographic units for gender group
sum_diff_gender <- sum((census$male + census$female) - census$total_pop_18_o)

# Race
sum_diff_race <- sum((census$race1 + census$race2 + census$race3 + census$race4) - census$total_pop_18_o)

# Age
sum_diff_age <- sum((census$age1 + census$age2 + census$age3 + census$age4) - census$total_pop_18_o)

# Education
sum_diff_edu <- sum((census$n_bach + census$bach) - census$total_pop_18_o)

# Income
sum_diff_income <- sum((census$income1 + census$income2 + census$income3 + census$income4) - census$total_pop_18_o)

# Insurance
sum_diff_insured <- sum((census$insured + census$n_insured) - census$total_pop_18_o)

# Urban vs Not Urban
sum_diff_urban <- sum((census$urban + census$n_urban) - census$total_pop_18_o)

# Check if all results are equal to zero
checks <- list(
  gender = sum_diff_gender,
  race = sum_diff_race,
  age = sum_diff_age,
  edu = sum_diff_edu,
  income = sum_diff_income,
  insured = sum_diff_insured,
  urban = sum_diff_urban
)

# Print results
checks

# Second, checking if there are any negatives, this should return FALSE!! 
any(census_select < 0, na.rm = TRUE)

########################## CREATING NECESSARY ARRAYS PRIOR TO IPF ######################################

## --- Create Weights  --- ##

# Creating one set of weights for each constraint and one for starting
# these will stay empty for now and will be used in future iterations
# 3528 rows for individuals, 2198 columns for tracts

weights0 <- array(dim = c(nrow(selected_data), nrow(census_select)))
weights1 <- array(dim = c(nrow(selected_data), nrow(census_select)))
weights2 <- array(dim = c(nrow(selected_data), nrow(census_select)))
weights3 <- array(dim = c(nrow(selected_data), nrow(census_select)))
weights4 <- array(dim = c(nrow(selected_data), nrow(census_select)))
weights5 <- array(dim = c(nrow(selected_data), nrow(census_select)))
weights6 <- array(dim = c(nrow(selected_data), nrow(census_select)))
weights7 <- array(dim = c(nrow(selected_data), nrow(census_select)))

weights0[, ] <- 1  # sets initial weights to 1


## --- Create Survey Aggregate Arrays  --- ##

# Creating an array for geographic aggregate data
# 2169 rows for each zone, 10 columns for each category of spatial data


cen.agg <- array(dim = c(nrow(census_select), ncol(census_select)-1))
cen.agg1 <- array(dim = c(nrow(census_select), ncol(census_select)-1))
cen.agg2 <- array(dim = c(nrow(census_select), ncol(census_select)-1))
cen.agg3 <- array(dim = c(nrow(census_select), ncol(census_select)-1))
cen.agg4 <- array(dim = c(nrow(census_select), ncol(census_select)-1))
cen.agg5 <- array(dim = c(nrow(census_select), ncol(census_select)-1))
cen.agg6 <- array(dim = c(nrow(census_select), ncol(census_select)-1))
cen.agg7 <- array(dim = c(nrow(census_select), ncol(census_select)-1))


########################## CONDUCTING IPF ITERATIONS  ######################################

## --- Calculate Aggregate Values based on Binary Individual-Level Data   --- ##

#  removing first columns from datasets so that ID attributes are not included in IPF procedure
census_select2 <- census_select[, -1]
selected_data2 <- selected_data[, -1]

#** RE-RUN FROM HERE! see line 497
# Iterate through each row of the spatial aggregate data (census tract)
for (i in 1:nrow(census_select2)) {
  # Calculates the aggregate values for the i-th row
  # Multiplies each column of the binary individual level data by the corresponding column in the i-th column of the weights0 array
  # Then sums up these values columnwise, resulting in aggregate values for each category
  # These aggregate values are assigned to the i-th row of the dataframe (USd.agg)
  
  # For example, for the first row of all.msim, 
  # the aggregate values are calculated by summing up the products of each column 
  # in USd.cat with the corresponding column in the first row of weights0
  
  cen.agg[i, ] <- colSums(selected_data2 * weights0[, i])
}


## --- Evaluating Results from First Iteration   --- ##

# creates a scatter plot comparing the model output 
plot(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg)), xlab = "Constraints", 
     ylab = "Model output")
abline(a = 0, b = 1)

# Calculating correlation 
cor(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg)))

################ CONSTRAINT 1: AGE ###################
## Adjusting weights based on ratios between individual-level and spatial aggregate data
## Then using the adjusted weights to  re-calculate the aggregate values 

# Iterate through each row of spatial aggregate data 
# For each row, we are aiming to calculate ratios between aggregate and individual-level data for each age group/range
for (j in 1:nrow(census_select2)) {
  # selects rows from an index where age in the survey data is the first category (18-29), 
  # then assigns values from retrieving value from the j-th row and 1st column of census data, 
  # then divides by the value from the j-th row and 1st column of the cen.agg data
  weights1[which(data$age1 == 1), j] <- census_select2[j, 7]/cen.agg[j, 7]
  weights1[which(data$age2 == 1), j] <- census_select2[j, 8]/cen.agg[j, 8]
  weights1[which(data$age3 == 1), j] <- census_select2[j, 9]/cen.agg[j, 9]
  weights1[which(data$age4 == 1), j] <- census_select2[j, 10]/cen.agg[j, 10]
}
# Iterate over each row of the spatial aggregate data to calculate aggregate values with adjusted weights
for (i in 1:nrow(census_select2)) {
  # sums up the products of each column in census data, weights0, weights1 
  cen.agg1[i, ] <- colSums(selected_data2 * weights0[, i] * weights1[, i])
}


## --- Evaluating Results from Second Iteration   --- ##
# creates a scatter plot comparing the model output 
plot(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg1)), xlab = "Constraints", 
     ylab = "Model output")
abline(a = 0, b = 1)

# Calculating correlation 
cor(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg1)))

################ CONSTRAINT 2: SEX ###################

# Iterate through each row of spatial aggregate data 
# For each row, we are aiming to calculate ratios between aggregate and individual-level data for each gender
for (j in 1:nrow(census_select2)) {
  # selects rows from an index where gender in the survey dataset is male, 
  # then assigns values from retrieving value from the j-th row and 4th column of census data, 
  # then divides by the value from the j-th row and 1st column of the cen.agg data
  weights2[which(data$male == 1), j] <- census_select2[j, 1]/cen.agg1[j, 1]
  weights2[which(data$female == 1), j] <- census_select2[j, 2]/cen.agg1[j, 2]
}

for (i in 1:nrow(census_select2)) {
  cen.agg2[i, ] <- colSums(selected_data2 * weights0[, i] * weights1[, i] * weights2[,i])
}

## --- Evaluating Results from THIRD Iteration   --- ##
# creates a scatter plot comparing the model output 
plot(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg2)), xlab = "Constraints", 
     ylab = "Model output")
abline(a = 0, b = 1)

# Calculating correlation 
cor(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg2)))

################ CONSTRAINT 3: RACE ###################

# Iterate through each row of spatial aggregate data 
# For each row, we are aiming to calculate ratios between aggregate and individual-level data for each race
for (j in 1:nrow(census_select2)) {
  weights3[which(data$race1 == 1), j] <- census_select2[j, 3]/cen.agg2[j,3]
  weights3[which(data$race2 == 1), j] <- census_select2[j, 4]/cen.agg2[j,4]
  weights3[which(data$race3 == 1), j] <- census_select2[j, 5]/cen.agg2[j,5]
  weights3[which(data$race4 == 1), j] <- census_select2[j, 6]/cen.agg2[j,6]
}
for (i in 1:nrow(census_select2)) {
  cen.agg3[i, ] <- colSums(selected_data2 * weights0[, i] * weights1[, i] * weights2[,i]*weights3[,i])}

## --- Evaluating Results from fourth Iteration   --- ##
# creates a scatter plot comparing the model output 
plot(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg3)), xlab = "Constraints", 
     ylab = "Model output")
abline(a = 0, b = 1)

# Calculating correlation 
cor(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg3)))

################ CONSTRAINT 4: EDUCATION ###################

# Iterate through each row of spatial aggregate data 
# For each row, we are aiming to calculate ratios between aggregate and individual-level data for each education
for (j in 1:nrow(census_select2)) {
  weights4[which(data$n_bach == 1), j] <- census_select2[j, 11]/cen.agg3[j,11]
  weights4[which(data$bach == 1), j] <- census_select2[j, 12]/cen.agg3[j,12]
}
for (i in 1:nrow(census_select2)) {
  cen.agg4[i, ] <- colSums(selected_data2 * weights0[, i] * weights1[, i] * weights2[,i]*weights3[,i]*weights4[,i])}

## --- Evaluating Results from fourth Iteration   --- ##
# creates a scatter plot comparing the model output 
plot(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg4)), xlab = "Constraints", 
     ylab = "Model output")
abline(a = 0, b = 1)

# Calculating correlation 
cor(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg4)))

################ CONSTRAINT 5: INCOME ###################

# Iterate through each row of spatial aggregate data 
# For each row, we are aiming to calculate ratios between aggregate and individual-level data for each income level
for (j in 1:nrow(census_select2)) {
  weights5[which(data$income1 == 1), j] <- census_select2[j, 13]/cen.agg4[j,13]
  weights5[which(data$income2 == 1), j] <- census_select2[j, 14]/cen.agg4[j,14]
  weights5[which(data$income3 == 1), j] <- census_select2[j, 15]/cen.agg4[j,15]
  weights5[which(data$income4 == 1), j] <- census_select2[j, 16]/cen.agg4[j,16]
}

for (i in 1:nrow(census_select2)) {
  cen.agg5[i, ] <- colSums(selected_data2 * weights0[, i] * weights1[, i] * weights2[,i]*weights3[,i]*weights4[,i]*weights5[,i])}


## --- Evaluating Results from fifth Iteration   --- ##
# creates a scatter plot comparing the model output 
plot(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg5)), xlab = "Constraints", 
     ylab = "Model output")
abline(a = 0, b = 1)

# Calculating correlation 
cor(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg5)))

################ CONSTRAINT 6: HEALTH INSURANCE ###################

# Iterate through each row of spatial aggregate data 
# For each row, we are aiming to calculate ratios between aggregate and individual-level data for each health insurance level
for (j in 1:nrow(census_select2)) {
  weights6[which(data$insured == 1), j] <- census_select2[j, 17]/cen.agg5[j,17]
  weights6[which(data$n_insured == 1), j] <- census_select2[j, 18]/cen.agg5[j,18]
}

for (i in 1:nrow(census_select2)) {
  cen.agg6[i, ] <- colSums(selected_data2 * weights0[, i] * weights1[, i] * weights2[,i]*weights3[,i]*weights4[,i]*weights5[,i]*weights6[,i])}


## --- Evaluating Results from sixth Iteration   --- ##
# creates a scatter plot comparing the model output 
plot(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg6)), xlab = "Constraints", 
     ylab = "Model output")
abline(a = 0, b = 1)

# Calculating correlation 
cor(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg6)))

################ CONSTRAINT 7: URBAN ###################

# Iterate through each row of spatial aggregate data 
# For each row, we are aiming to calculate ratios between aggregate and individual-level data for each diabetes level
for (j in 1:nrow(census_select2)) {
  weights7[which(data$urban == 1), j] <- census_select2[j, 19]/cen.agg6[j,19]
  weights7[which(data$n_urban == 1), j] <- census_select2[j, 20]/cen.agg6[j,20]
}

weights8 <- weights0 * weights1 * weights2 * weights3 * weights4 * weights5* weights6 * weights7

for (i in 1:nrow(census_select2)) {
  cen.agg7[i, ] <- colSums(selected_data2 * weights8[, i])}



## --- Evaluating Results from seventh Iteration   --- ##
# creates a scatter plot comparing the model output 
plot(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg7)), xlab = "Constraints", 
     ylab = "Model output")
abline(a = 0, b = 1)

# Calculating correlation 
cor(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg7)))


################ PERFORM FURTHER ITERATIONS ###################

# using results from initial results as starting point
weights0 <- weights8
cen.agg.1 <- cen.agg 

#** RE-RUN SAME ITERATIONS AS BEFORE...
#*
# Iterate through each row of the spatial aggregate data (e.g., census tract)
for (i in 1:nrow(census_select2)) {
  # Calculates the aggregate values for the i-th row
  # Multiplies each column of the binary individual level data by the corresponding column in the i-th column of the weights0 array
  # Then sums up these values columnwise, resulting in aggregate values for each category
  # These aggregate values are assigned to the i-th row of the dataframe (USd.agg)
  
  # For example, for the first row of all.msim, 
  # the aggregate values are calculated by summing up the products of each column 
  # in USd.cat with the corresponding column in the first row of weights0
  
  cen.agg[i, ] <- colSums(selected_data2 * weights0[, i])
}


## --- Evaluating Results from First Iteration   --- ##

# creates a scatter plot comparing the model output 
plot(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg)), xlab = "Constraints", 
     ylab = "Model output")
abline(a = 0, b = 1)

# Calculating correlation 
cor(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg)))

################ CONSTRAINT 1: AGE ###################
## Adjusting weights based on ratios between individual-level and spatial aggregate data
## Then using the adjusted weights to  re-calculate the aggregate values 

# Iterate through each row of spatial aggregate data 
# For each row, we are aiming to calculate ratios between aggregate and individual-level data for each age group/range
for (j in 1:nrow(census_select2)) {
  # selects rows from an index where age in the survey data is the first category (18-29), 
  # then assigns values from retrieving value from the j-th row and 1st column of census data, 
  # then divides by the value from the j-th row and 1st column of the cen.agg data
  weights1[which(data$age1 == 1), j] <- census_select2[j, 7]/cen.agg[j, 7]
  weights1[which(data$age2 == 1), j] <- census_select2[j, 8]/cen.agg[j, 8]
  weights1[which(data$age3 == 1), j] <- census_select2[j, 9]/cen.agg[j, 9]
  weights1[which(data$age4 == 1), j] <- census_select2[j, 10]/cen.agg[j, 10]
}
# Iterate over each row of the spatial aggregate data to calculate aggregate values with adjusted weights
for (i in 1:nrow(census_select2)) {
  # sums up the products of each column in census data, weights0, weights1 
  cen.agg1[i, ] <- colSums(selected_data2 * weights0[, i] * weights1[, i])
}


## --- Evaluating Results from Second Iteration   --- ##
# creates a scatter plot comparing the model output 
plot(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg1)), xlab = "Constraints", 
     ylab = "Model output")
abline(a = 0, b = 1)

# Calculating correlation 
cor(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg1)))

################ CONSTRAINT 2: SEX ###################

# Iterate through each row of spatial aggregate data 
# For each row, we are aiming to calculate ratios between aggregate and individual-level data for each gender
for (j in 1:nrow(census_select2)) {
  # selects rows from an index where gender in the survey dataset is male, 
  # then assigns values from retrieving value from the j-th row and 4th column of census data, 
  # then divides by the value from the j-th row and 1st column of the cen.agg data
  weights2[which(data$male == 1), j] <- census_select2[j, 1]/cen.agg1[j, 1]
  weights2[which(data$female == 1), j] <- census_select2[j, 2]/cen.agg1[j, 2]
}

for (i in 1:nrow(census_select2)) {
  cen.agg2[i, ] <- colSums(selected_data2 * weights0[, i] * weights1[, i] * weights2[,i])
}

## --- Evaluating Results from THIRD Iteration   --- ##
# creates a scatter plot comparing the model output 
plot(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg2)), xlab = "Constraints", 
     ylab = "Model output")
abline(a = 0, b = 1)

# Calculating correlation 
cor(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg2)))

################ CONSTRAINT 3: RACE ###################

# Iterate through each row of spatial aggregate data 
# For each row, we are aiming to calculate ratios between aggregate and individual-level data for each race
for (j in 1:nrow(census_select2)) {
  weights3[which(data$race1 == 1), j] <- census_select2[j, 3]/cen.agg2[j,3]
  weights3[which(data$race2 == 1), j] <- census_select2[j, 4]/cen.agg2[j,4]
  weights3[which(data$race3 == 1), j] <- census_select2[j, 5]/cen.agg2[j,5]
  weights3[which(data$race4 == 1), j] <- census_select2[j, 6]/cen.agg2[j,6]
}
for (i in 1:nrow(census_select2)) {
  cen.agg3[i, ] <- colSums(selected_data2 * weights0[, i] * weights1[, i] * weights2[,i]*weights3[,i])}

## --- Evaluating Results from fourth Iteration   --- ##
# creates a scatter plot comparing the model output 
plot(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg3)), xlab = "Constraints", 
     ylab = "Model output")
abline(a = 0, b = 1)

# Calculating correlation 
cor(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg3)))

################ CONSTRAINT 4: EDUCATION ###################

# Iterate through each row of spatial aggregate data 
# For each row, we are aiming to calculate ratios between aggregate and individual-level data for each education
for (j in 1:nrow(census_select2)) {
  weights4[which(data$n_bach == 1), j] <- census_select2[j, 11]/cen.agg3[j,11]
  weights4[which(data$bach == 1), j] <- census_select2[j, 12]/cen.agg3[j,12]
}
for (i in 1:nrow(census_select2)) {
  cen.agg4[i, ] <- colSums(selected_data2 * weights0[, i] * weights1[, i] * weights2[,i]*weights3[,i]*weights4[,i])}

## --- Evaluating Results from fourth Iteration   --- ##
# creates a scatter plot comparing the model output 
plot(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg4)), xlab = "Constraints", 
     ylab = "Model output")
abline(a = 0, b = 1)

# Calculating correlation 
cor(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg4)))

################ CONSTRAINT 5: INCOME ###################

# Iterate through each row of spatial aggregate data 
# For each row, we are aiming to calculate ratios between aggregate and individual-level data for each income level
for (j in 1:nrow(census_select2)) {
  weights5[which(data$income1 == 1), j] <- census_select2[j, 13]/cen.agg4[j,13]
  weights5[which(data$income2 == 1), j] <- census_select2[j, 14]/cen.agg4[j,14]
  weights5[which(data$income3 == 1), j] <- census_select2[j, 15]/cen.agg4[j,15]
  weights5[which(data$income4 == 1), j] <- census_select2[j, 16]/cen.agg4[j,16]
}

for (i in 1:nrow(census_select2)) {
  cen.agg5[i, ] <- colSums(selected_data2 * weights0[, i] * weights1[, i] * weights2[,i]*weights3[,i]*weights4[,i]*weights5[,i])}


## --- Evaluating Results from fifth Iteration   --- ##
# creates a scatter plot comparing the model output 
plot(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg5)), xlab = "Constraints", 
     ylab = "Model output")
abline(a = 0, b = 1)

# Calculating correlation 
cor(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg5)))

################ CONSTRAINT 6: HEALTH INSURANCE ###################

# Iterate through each row of spatial aggregate data 
# For each row, we are aiming to calculate ratios between aggregate and individual-level data for each health insurance level
for (j in 1:nrow(census_select2)) {
  weights6[which(data$insured == 1), j] <- census_select2[j, 17]/cen.agg5[j,17]
  weights6[which(data$n_insured == 1), j] <- census_select2[j, 18]/cen.agg5[j,18]
}

for (i in 1:nrow(census_select2)) {
  cen.agg6[i, ] <- colSums(selected_data2 * weights0[, i] * weights1[, i] * weights2[,i]*weights3[,i]*weights4[,i]*weights5[,i]*weights6[,i])}


## --- Evaluating Results from sixth Iteration   --- ##
# creates a scatter plot comparing the model output 
plot(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg6)), xlab = "Constraints", 
     ylab = "Model output")
abline(a = 0, b = 1)

# Calculating correlation 
cor(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg6)))

################ CONSTRAINT 7: URBAN ###################

# Iterate through each row of spatial aggregate data 
# For each row, we are aiming to calculate ratios between aggregate and individual-level data for each diabetes level
for (j in 1:nrow(census_select2)) {
  weights7[which(data$urban == 1), j] <- census_select2[j, 19]/cen.agg6[j,19]
  weights7[which(data$n_urban == 1), j] <- census_select2[j, 20]/cen.agg6[j,20]
}

weights8 <- weights0 * weights1 * weights2 * weights3 * weights4 * weights5* weights6 * weights7

for (i in 1:nrow(census_select2)) {
  cen.agg7[i, ] <- colSums(selected_data2 * weights8[, i])}



## --- Evaluating Results from seventh Iteration   --- ##
# creates a scatter plot comparing the model output 
plot(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg7)), xlab = "Constraints", 
     ylab = "Model output")
abline(a = 0, b = 1)

# Calculating correlation 
cor(as.vector(as.matrix(census_select2)), as.vector(as.matrix(cen.agg7)))


############## CHECKING AND SAVING MARGINAL DATA (WEIGHTS) FROM IPF ###########################
# Check output before continuing!!! Print difference between final weights sum and total population sum. This should equal almost 0!
sum(weights8)-sum(census$total_pop_18_o)

# Save weights as a dataframe, then write to an excel file
df <- as.data.frame(weights8)
write_xlsx(df, "Insert file path here!.xlsx")

################# INTEGERISATION ##############################
# Note: This step is computationally extensive, may need a cluster or will take longer to run

# Read in the marginals data if needed 
# marg <- read_excel("Insert file name here.xlsx")

# if you do not need to read in a file, transfer weights 8 results to a new dataframe
marg <- weights8

# Convert to matrix
matrix_mdf <- as.matrix(marg)

## Function to implement the TRS integerisation approach 
# Review these sources for more details on this approach: 
# https://www.sciencedirect.com/science/article/pii/S0198971513000240
# https://www.taylorfrancis.com/books/mono/10.1201/9781315381640/spatial-microsimulation-robin-lovelace-morgane-dumont

int_trs <- function(x){
  # converting to a vector
  xv <- as.vector(x) 
  # integer part of each weight is obtained by rounding down each element to the nearest integer
  xint <- floor(xv) 
  # decimal part of each weight is calculated by subtracting the integer part from the original weight vector
  r <- xv - xint 
  # the sum of all decimal parts is rounded to obtain an integer value representing the deficit population
  def <- round(sum(r)) 
  # random individuals are sampled with probabilities proportional to the decimal parts of their weights; 
  # these individuals represent the ones where weights need to be increased to reach the desired integer population
  topup <- sample(length(x), size = def, prob = r)
  # the weights are 'topped up' to reach the desired integer population, 
  # meaning that integer weights of the selected individuals are incremented by 1
  xint[topup] <- xint[topup] + 1
  # reshaping integer weights into a matrix
  dim(xint) <- dim(x)
  # dimension names are set to match those of the input
  dimnames(xint) <- dimnames(x)
  xint
}

## Applying the function to the matrix of marginals
result <- int_trs(matrix_mdf)

# Convert the geographic zone unique IDs (i.e., 'GEOID_Data') column to a vector and transpose it
geo_row_names <- t(census$FIPS)

# Set the column names of your resulting data frame to the transposed vector with unique IDs
colnames(result) <- geo_row_names

# Add the survey respondents' ID  as a new column to the resulting data frame
result <- cbind(ID = data$ID, result)

# Save integer results to a dataframe, and save as an Excel file
df <- as.data.frame(result)
write_xlsx(df, "US_counties_part1_BRFSS22_ints_level1.xlsx")


################# EXPANSION ##############################

# Read in the integers data if needed 
#ints <- read_excel("Insert file name here!.xlsx")

# Or, if you are continuing from lines above, re-established integers as a new dataframe 
ints <- df

# Convert to long data - reshapes the data so that each row represents a unique combination of an Individual's ID and a GEOID (e.g., county FIPS code), with a count
long_data <- ints %>%
  pivot_longer(cols = -1, names_to = "GEOID", values_to = "Count") %>%
  rename(IndividualID = 1)

# Expand the data based on the counts - replicates rows based on the value in the Count column
expanded_data <- long_data %>%
  uncount(Count)

# Writing expansion results to a CSV sheet (too large for excel)
df <- as.data.frame(expanded_data)
write.csv(df, "Insert file name here!.csv")

################ REPLICATING INDIVIDUALS & AGGREGATING HEALTH OUTCOMES AT SMALL AREA LEVELS ################ 

# Read in the individual-level health survey data (again, if needed- should already be read in from first part of the script)
data <- read_excel("Insert file name here!.xlsx")

# Read in the expanded dataset, if needed
expanded_data <- read.csv("Insert file name here!.xlsx")

# Joining the health behavior and outcome data (can bring over any attribute if interested) from the survey dataset to the expanded dataset (left join to keep all rows from expanded dataset)
merged_data <- left_join(expanded_data, select(data,
                                               ID,
                                               leisure_time,
                                               arthritis,
                                               asthma,
                                               cancer,
                                               #high_cholesterol,
                                               #high_bp,
                                               kidney_disease,
                                               copd,
                                               heart_disease,
                                               depression,
                                               diabetes,
                                               obesity,
                                               stroke,
                                               binge_drinking,
                                               smoker
                                                ), by = c("IndividualID" = "ID"))

# Writing replicated results to a csv sheet
df <- as.data.frame(merged_data)
write.csv(df, "Insert file name here!.csv")

# Summarize the health risk behavior and outcome data by GEOID and counts the total synthetic population per GEOID
summary_data <- merged_data %>%
  group_by(CensusTractID) %>%
  summarize(
    total_leisure_time = sum(leisure_time, na.rm = TRUE),
    total_arthritis = sum(arthritis, na.rm = TRUE),
    total_asthma = sum(asthma, na.rm = TRUE),
    total_cancer = sum(cancer, na.rm = TRUE),
    total_high_cholesterol = sum(high_cholesterol, na.rm = TRUE),
    total_high_bp = sum(high_bp, na.rm = TRUE),
    total_kidney_disease = sum(kidney_disease, na.rm = TRUE),
    total_copd = sum(copd, na.rm = TRUE),
    total_heart_disease = sum(heart_disease, na.rm = TRUE),
    total_depression = sum(depression, na.rm = TRUE),
    total_diabetes = sum(diabetes, na.rm = TRUE),
    total_obesity = sum(obesity, na.rm = TRUE),
    total_stroke = sum(stroke, na.rm = TRUE),
    total_binge_drinking = sum(binge_drinking, na.rm = TRUE),
    total_smoker = sum(smoker, na.rm = TRUE),
    total_population = n()
  ) %>%
  ## Calculating percentages in each geographic unit (e.g., county)
  mutate(
    perc_sim_leisure_time = (total_leisure_time / total_population) * 100,
    perc_sim_arthritis = (total_arthritis / total_population) * 100,
    perc_sim_asthma = (total_asthma / total_population) * 100,
    perc_sim_cancer = (total_cancer / total_population) * 100,
    perc_sim_high_cholesterol = (total_high_cholesterol / total_population) * 100,
    perc_sim_high_bp = (total_high_bp / total_population) * 100,
    perc_sim_kidney_disease = (total_kidney_disease / total_population) * 100,
    perc_sim_copd = (total_copd / total_population) * 100,
    perc_sim_heart_disease = (total_heart_disease / total_population) * 100,
    perc_sim_depression = (total_depression / total_population) * 100,
    perc_sim_diabetes = (total_diabetes / total_population) * 100,
    perc_sim_obesity = (total_obesity / total_population) * 100,
    perc_sim_stroke = (total_stroke / total_population) * 100,
    perc_sim_binge_drinking = (total_binge_drinking / total_population) * 100,
    perc_sim_smoker = (total_smoker / total_population) * 100
  )

# Writing joined and summed  results to a Excel sheet
df <- as.data.frame(summary_data)
write_xlsx(df, "Insert file name here!.xlsx")

### THIS IS THE END OF LEVEL ONE OF SHAPE!!! *** REMEMBER TO TAKE POPULATION COUNTS FOR HEALTH RISK BEHAVIORS (e.g., SMOKERS) AND JOIN TO SPATIALLY AGGREGATED DATASET TO USE IN LEVEL 2!